# -*- coding: utf-8 -*-
"""Identification of mutation in Cancer Gene

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Qql8_SH7oZVwf-mLjVRuYaYUH2I0hgha
"""

print('Data source import complete.')

"""# **Project: Identification of Cancer-Causing Mutations**
*(Dataset Source: ClinVar)*

**Overview** In this project, we address the challenge of distinguishing between **Driver** (cancer-causing) and **Passenger** (neutral) mutations. Due to the restricted access of cancer-specific datasets (like TCGA), we utilize the **ClinVar** public dataset as a proxy, where:
- Pathogenic variants serve as the positive class (analogous to Cancer Drivers).
- Benign variants serve as the negative class (Passenger/Neutral).

**Workflow**
1. Data Cleaning & Preprocessing:
  - Filtered the ClinVar dataset to isolate entries with definitive Pathogenic vs Benign labels.
  - Handled missing values in critical columns and encoded categorical variables (e.g., Amino_acids, Ref, Alt).

2. Exploratory Data Analysis (EDA):
  - Analyzed the distribution of variants across different chromosomes.
  - Addressed Class Imbalance (as neutral mutations often outnumber pathogenic ones) to prevent model bias.

3. Feature Selection:
  - Selected biological features such as Allele Frequency and Molecular Consequence to serve as predictors.

4. Model Building:
  - Trained supervised machine learning models (Logistic Regression, Random Forest, etc.) to classify mutations based on their feature profiles.

**Impact:** This model demonstrates a computational approach to **Prioritizing Cancer Mutations**, helping researchers filter through thousands of genetic variants to identify potential therapeutic targets.
"""

# Commented out IPython magic to ensure Python compatibility.
# imports
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import scipy.stats as stats
# %matplotlib inline
from scipy import stats
from sklearn.preprocessing import LabelEncoder
import seaborn as sns
import matplotlib.pyplot as plt
from scipy.stats import stats
from scipy.stats import boxcox
from scipy.stats.mstats import winsorize
from sklearn.feature_selection import SelectKBest, chi2
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.linear_model import Lasso
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.metrics import confusion_matrix, r2_score, mean_squared_error
from sklearn.feature_selection import RFE
from sklearn.ensemble import RandomForestClassifier
import xgboost as xgb

import os
current_directory = os.getcwd()
print(f"Current working directory: {current_directory}")

df = pd.read_csv('data\clinvar_conflicting.csv\clinvar_conflicting.csv', low_memory=False)

df['CLASS'].value_counts()

df.columns

df.head()

df.info()

df.shape

"""## Data Cleaning

The info above indicates that the DataFrame has a total of 46 parameters (fields) that pertain to the genetic mutation samples in the database. We start by examining the variables and begin cleaning the data.

Data cleaning typically involves examining null values, detecting outliers, and visualizing initial relationships between categorical and continuous variables.
"""

# we are creating new dataframe var_df
var_df = pd.DataFrame(columns=['variable_name', 'data_type', 'missing_percentage', 'flag', 'unique_values_count'])

missing_percentages = df.isnull().mean() * 100
missing_percentages = missing_percentages.sort_values(ascending=False)

for col in df.columns:
    data_type = df[col].dtype
    missing_percentage = missing_percentages[col]
    unique_values_count = df[col].nunique()
    if data_type == 'int64' or data_type == 'float64':
        flag = 'numeric'
    else:
        flag = 'categorical'
    var_df = pd.concat([var_df, pd.DataFrame({'variable_name': [col], 'data_type': [data_type], 'missing_percentage': [missing_percentage], 'flag': [flag], 'unique_values_count': [unique_values_count]})], ignore_index=True)

var_df.info()
var_df

# sort variables by missing percentage value
var_df_sorted = var_df.sort_values(by='missing_percentage')
var_df_sorted.reset_index(drop=True, inplace=True)

var_df_sorted

"""**Dropping Empty Columns** The chart indicates that 9 columns are virtually empty, containing less than 0.5% actual data. To prevent model noise, we implement a cleanup rule: any feature with **>99%** missing values is immediately removed from the dataset."""

var_df = var_df_sorted.copy()

threshold = 99
var_df = var_df[var_df['missing_percentage'] <= threshold]

var_df

"""**Now removing the the cols with more that 99% from the dataframe**"""

threshold = 99

missing_percentages = df.isnull().mean() * 100
columns_to_drop = missing_percentages[missing_percentages > threshold].index.tolist()

df = df.drop(columns=columns_to_drop)

df.info()

"""Lets understand the relationships between variables to better understand inconsistencies and errors in the data. A heat matrix will give us a good initial indication of correlations between **numeric variables**."""

numerical_columns = df.select_dtypes(include=['int64', 'float64'])
corr_matrix = numerical_columns.corr()
plt.figure(figsize=(10, 8))
sns.heatmap(corr_matrix, cmap='coolwarm', annot=True, fmt='.2f')
plt.title('Correlation Matrix Heatmap')
plt.show()

df.head()

"""With respect to this project and experiment, there are several columns amongst the main 'df' dataframe that can be dropped.

1. BAM_EDIT = Binary Map Alignment, indicates whether it's stored in a particular database, not relevant.
2. INTRON = severely low amount of non-null values, contains date
3. EXON = contains dates, not performing time series, not relevant
4. CLNDISB = Provides MedGen database identifiers, not relevant
5. CLNHGVS = provides database identifier, not relevant
6. MC = repeat of Consequence with additional database identifier
7. CLNVI = lab location identifier, not relevant for current project.
8. SYMBOL = another identifier, redundant
9. Feature: Value included in consequence column
10. Feature_type: Value included in consequence column
11. BIOTYPE: Value included in consequence column
12. CADD_RAW: directly related to CADD_PHRED - only CADD_PHRED is needed with respect to genetic mutations, it uses a scale that is easier to work with.
"""

df.drop(['BAM_EDIT', 'EXON', 'CLNDISDB', 'CLNHGVS',
         'MC', 'CLNVI', 'SYMBOL', 'Feature', 'Feature_type',
         'BIOTYPE', 'INTRON', 'CADD_RAW'], axis=1, inplace=True)

df.info()

numerical_columns.info()

numerical_columns.head()

object_cols = df.select_dtypes(include=['object'])
object_cols.info()

object_cols.head()

"""The object and numerical columns have been separated for initial visualization. There still appear to be some errors so we will handle such as necessary."""

still_missing = pd.DataFrame()

for column in df.columns:
    if df[column].isnull().any():
        still_missing[column] = df[column]

print("Columns with missing values:")
still_missing.info()

still_missing.nunique()

for column in still_missing.columns:
    if column == 'BLOSUM62':
        still_missing[column] = still_missing[column].fillna(method='ffill')
    elif still_missing[column].dtype == 'object':
        still_missing[column] = still_missing[column].fillna(method='ffill')
    elif still_missing[column].dtype == 'float64':
        still_missing[column] = still_missing[column].interpolate()   ## mean of surronding values

still_missing['LoFtool'] = still_missing['LoFtool'].fillna(0)

still_missing.info()

df.update(still_missing)
df.info()

df_original = df.copy()

"""All null values have been filled in the dataframe. The next step in cleaning is to visualize outliers and distributions. To do this, we must convert the object columns to numeric first."""

label_encoder = LabelEncoder()

for column in df.columns:
    if df[column].dtype == 'object':
        df[column] = label_encoder.fit_transform(df[column])

df.info()

for column in df.columns:
    if df[column].dtype == 'int32':
        df[column] = df[column].astype('int64')

df.info()

num_columns = 3
num_rows = (len(df.columns) - 1) // num_columns + 1

fig, axes = plt.subplots(num_rows, num_columns, figsize=(15, 40))

for i, column in enumerate(df.columns):
    row = i // num_columns
    col = i % num_columns
    ax = axes[row][col]
    df.boxplot(column=column, ax=ax)
    ax.set_title(column)

plt.tight_layout()
plt.show()

"""**Analysis of Allele Frequency (AF) Outliers** The boxplots reveal significant outliers in the three Allele Frequency columns: AF_ESP, AF_EXAC, and AF_TGP. While statistically noisy, these features are highly correlated and biologically critical. They represent the **prevalence** of a variant derived from three distinct large-scale databases:
- ESP: NHLBI Exome Sequencing Project (Disease-focused).
- ExAC: Exome Aggregation Consortium (Large-scale aggregation).
- TGP: 1000 Genomes Project (Global population diversity).
Despite coming from different sources, they measure the same theoretical value. The "outliers" likely represent common polymorphisms (high frequency), whereas the majority of data points represent rare mutations (near-zero frequency), making these distributions essential for distinguishing common variants from pathogenic drivers.

# Data Exploratory Analysis
"""

fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(10, 4))

ax1.hist(df['AF_ESP'], bins=10, density=True)
ax1.set_title('AF_ESP Distribution')

ax2.hist(df['AF_EXAC'], bins=10, density=True)
ax2.set_title('AF_EXAC Distribution')

ax3.hist(df['AF_TGP'], bins=10, density=True)
ax3.set_title('AF_TGP Distribution')

plt.tight_layout()

plt.show()

"""While the Allele Frequency columns appear redundant—sharing right-skewed distributions, high correlation, and no reported nulls—this completeness is deceptive. Missing values are encoded as '0', which Python treats as valid data. We must therefore analyze the zero-counts to reveal the true extent of missing data."""

allele_df = df[['AF_ESP', 'AF_EXAC', 'AF_TGP']]

allele_df.info()

# initiate count of three new variables

esp_zeros = 0
exac_zeros = 0
tgp_zeros = 0

# iterate through allele_df and print count of zeroes

for column in allele_df.columns:
    column_values = allele_df[column].values
    zeros_count = len(column_values[column_values == 0])

    if column == 'AF_ESP':
        esp_zeros += zeros_count
    elif column == 'AF_EXAC':
        exac_zeros += zeros_count
    elif column == 'AF_TGP':
        tgp_zeros += zeros_count

print("Count of zeroes (missing values) in AF_ESP column:", esp_zeros)
print("Count of zeroes (missing values) in AF_EXAC column:", exac_zeros)
print("Count of zeroes (missing values) in AF_TGP column:", tgp_zeros)

esp_missing = round((esp_zeros / len(allele_df)) * 100, 2)
exac_missing = round((exac_zeros / len(allele_df)) * 100, 2)
tgp_missing = round((tgp_zeros / len(allele_df)) * 100, 2)

print("Percentage of actual missing values in AF_ESP column:", esp_missing)
print("Percentage of actual missing values in AF_EXAC column:", exac_missing)
print("Percentage of actual missing values in AF_TGP column:", tgp_missing)

"""All three columns appear to have different counts of zero. Thus, they have different counts of actual null values.

ESP and TGP have similar missing percentages at 54.89 and 58.25, respectively. EXAC, however, has only 36.89 % missing.
The next step is to visualize the distributions after removing null-values.
"""

for column in allele_df.columns:
    allele_df.loc[allele_df[column] == 0, column] = None

allele_df.info()

"""The 'allele_df' dataframe above now has the correct count of non-null values in each column."""

methods = ['mean', 'median', 'interpolation']

original_skewness = allele_df.skew()

results = {}

for method in methods:
    if method == 'mean':
        filled_df = allele_df.fillna(allele_df.mean())
    elif method == 'median':
        filled_df = allele_df.fillna(allele_df.median())
    elif method == 'interpolation':
        filled_df = allele_df.interpolate()

    # Calculate skewness
    skewness = filled_df.skew()
    results[method] = {'skewness': skewness, }

for method in methods:
    print("Skewness:\n", results[method]['skewness'])
    print()

"""The skew of the three types of null value filling are above. Interpolation proves to invoke the smallest skew on the data; thus, interpolation will be used for all three columns."""

allele_df = allele_df.interpolate()


allele_df_boxcox = allele_df.copy()
for column in allele_df_boxcox.columns:
    transformed_data, _ = boxcox(allele_df_boxcox[column].dropna() + 1)  # Add 1 to avoid zero values
    allele_df_boxcox[column].loc[~allele_df_boxcox[column].isna()] = transformed_data

log_constant = 1
allele_df_log = np.log1p(allele_df + log_constant)


allele_df_winsorized = allele_df.copy()
for column in allele_df_winsorized.columns:
    allele_df_winsorized[column] = winsorize(allele_df_winsorized[column].dropna(), limits=[0.05, 0.05])


fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(18, 6))


allele_df_boxcox.boxplot(ax=axes[0])
axes[0].set_title("Box-Cox Transformed Boxplots")
axes[0].set_xticklabels(allele_df_boxcox.columns, rotation=45)
axes[0].set_xlabel("Columns")
axes[0].set_ylabel("Transformed Values")


allele_df_log.boxplot(ax=axes[1])
axes[1].set_title("Log Transformed Boxplots")
axes[1].set_xticklabels(allele_df_log.columns, rotation=45)
axes[1].set_xlabel("Columns")
axes[1].set_ylabel("Transformed Values")


allele_df_winsorized.boxplot(ax=axes[2])
axes[2].set_title("Winsorized Boxplots")
axes[2].set_xticklabels(allele_df_winsorized.columns, rotation=45)
axes[2].set_xlabel("Columns")
axes[2].set_ylabel("Transformed Values")


plt.tight_layout()

plt.show()

"""Clearly from the boxplot representations above we can see that Box-cox transformation transforms the outliers the best."""

df.update(allele_df_boxcox)
df.info()

num_columns = 3
num_rows = (len(df.columns) - 1) // num_columns + 1

fig, axes = plt.subplots(num_rows, num_columns, figsize=(15, 40))


for i, column in enumerate(df.columns):
    row = i // num_columns
    col = i % num_columns
    ax = axes[row][col]
    df.boxplot(column=column, ax=ax)
    ax.set_title(column)

plt.tight_layout()
plt.show()

z_scores = df.apply(stats.zscore)

z_score_threshold = 3
num_outliers = (np.abs(z_scores) > z_score_threshold).sum()

print("Number of Outliers:")
print(num_outliers)

df.info()

df.hist(figsize=(14, 10))
plt.tight_layout()
plt.show()

plt.figure(figsize=(18, 16))

correlation_matrix = df.corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', square=True)

plt.title('Correlation Heatmap')
plt.show()

"""The heatmap reveals distinct correlation patterns in the cleaned data. While strong correlations with the target variable suggest high predictive power, high correlations between features indicate potential multicollinearity. To address this trade-off and optimize model stability, we now proceed to Feature Engineering and Feature Selection."""

marker_size = 5
marker_alpha = 0.5

plt.scatter(df['AF_ESP'], df['AF_EXAC'], s=marker_size, alpha=marker_alpha)
plt.xlabel('AF_ESP')
plt.ylabel('AF_EXAC')
plt.title('Scatter Plot: AF_ESP vs AF_EXAC')
plt.show()

plt.scatter(df['AF_ESP'], df['AF_TGP'], s=marker_size, alpha=marker_alpha)
plt.xlabel('AF_ESP')
plt.ylabel('AF_TGP')
plt.title('Scatter Plot: AF_ESP vs AF_TGP')
plt.show()

plt.scatter(df['AF_EXAC'], df['AF_TGP'], s=marker_size, alpha=marker_alpha)
plt.xlabel('AF_EXAC')
plt.ylabel('AF_TGP')
plt.title('Scatter Plot: AF_EXAC vs AF_TGP')
plt.show()

plt.scatter(df['cDNA_position'], df['CDS_position'], s=marker_size, alpha=marker_alpha)
plt.xlabel('cDNA_position')
plt.ylabel('CDS_position')
plt.title('Scatter Plot: cDNA_position vs CDS_position')
plt.show()

"""# Feature Selection and Model Build

Here we are building model with the target variable being 'CLASS'. it classifies a mutation as pathogenic (Likely Cancer Causing) as 1 and non-pathogenic (Not-cancer cauing) as 0.
"""

X = df.drop('CLASS', axis=1)
y = df['CLASS']

# Preprocess the feature matrix to ensure non-negative values
scaler = MinMaxScaler()
X = scaler.fit_transform(X)

k = 10
selector = SelectKBest(score_func=chi2, k=k)
X_new = selector.fit_transform(X, y)

selected_indices = selector.get_support(indices=True)
selected_scores = selector.scores_[selected_indices]
selected_features = df.columns[selected_indices]

for feature, score in zip(selected_features, selected_scores):
    print(f"Feature: {feature}, Score: {score}")

"""![Screenshot 2025-12-02 001723.png](data:image/png;base64,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)"""

df['AF_avg'] = (df['AF_ESP'] + df['AF_EXAC'] + df['AF_TGP']) / 3
df.info()

corr_class = df[['CLASS', 'AF_avg', 'AF_ESP', 'AF_EXAC', 'AF_TGP', 'Consequence',
               'Codons', 'STRAND', 'SIFT', 'LoFtool', 'BLOSUM62']]
corr_class.corr()

corr_class.hist(figsize=(14, 10))
plt.tight_layout()
plt.show()

"""The histogram above displays the distributions of columns within our new 'corr_class' dataframe. This dataframe is a subset of the main 'df' dataframe that contains the selected features from the chi-squared test regarding 'CLASS' as the potential target variable.

#### Principal Component Analysis  [Failed]
"""

from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

X = df[['AF_avg', 'AF_ESP', 'AF_EXAC', 'AF_TGP']]

X = StandardScaler().fit_transform(X)

sklearn_pca = PCA(n_components=1)
df["pca_1"] = sklearn_pca.fit_transform(X)

print(
    'The percentage of total variance.\n',
    sklearn_pca.explained_variance_ratio_
)

df[['AF_avg', 'pca_1', 'AF_ESP', 'AF_EXAC', 'AF_TGP']].corr()

df_new = df.copy()

# Drop the specified columns
df_new.drop(['AF_ESP', 'AF_EXAC', 'AF_avg', 'AF_TGP'], axis=1, inplace=True)

X = df_new.drop('CLASS', axis=1)
y = df_new['CLASS']

# Preprocess the feature matrix to ensure non-negative values
scaler = MinMaxScaler()
X = scaler.fit_transform(X)

k = 10
selector = SelectKBest(score_func=chi2, k=k)
X_new = selector.fit_transform(X, y)

selected_indices = selector.get_support(indices=True)
selected_scores = selector.scores_[selected_indices]
selected_features = df_new.columns[selected_indices]

for feature, score in zip(selected_features, selected_scores):
    print(f"Feature: {feature}, Score: {score}")

"""Performing a chi-squared test proves that the 'pca_1' variable is not a good feature for the model. Let's explore a bit more."""

X = df.drop('CLASS', axis=1)
y = df['CLASS']

# Preprocess the feature matrix to ensure non-negative values
scaler = MinMaxScaler()
X = scaler.fit_transform(X)

k = 10
selector = SelectKBest(score_func=chi2, k=k)
X_new = selector.fit_transform(X, y)

selected_indices = selector.get_support(indices=True)
selected_scores = selector.scores_[selected_indices]
selected_features = df.columns[selected_indices]

for feature, score in zip(selected_features, selected_scores):
    print(f"Feature: {feature}, Score: {score}")

"""#### Using AF_AVG instead

Chi-squared test confirms that Allele Frequency features are significant predictors. However, given their strong inter-correlation (multicollinearity), retaining all three source columns is redundant. To preserve this critical biological signal while ensuring model stability, we select the aggregated AF_avg feature and drop the individual components
"""

df_three = df.copy()
df_three.drop(['AF_ESP', 'AF_TGP', 'AF_EXAC'], axis=1, inplace=True)

X = df_three.drop('CLASS', axis=1)
y = df['CLASS']

# Preprocess the feature matrix to ensure non-negative values
scaler = MinMaxScaler()
X = scaler.fit_transform(X)

k = 10
selector = SelectKBest(score_func=chi2, k=k)
X_new = selector.fit_transform(X, y)

selected_indices = selector.get_support(indices=True)
selected_scores = selector.scores_[selected_indices]
selected_features = df_three.columns[selected_indices]

for feature, score in zip(selected_features, selected_scores):
    print(f"Feature: {feature}, Score: {score}")

X_new.shape

"""# Applying ML and DL models on the Final Processed Dataset

# Logistic Regression
"""

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.2, random_state=42)

# Create and fit the logistic regression model
logreg = LogisticRegression()
logreg.fit(X_train, y_train)

# Make predictions on the testing set
y_pred = logreg.predict(X_test)

# Calculate evaluation metrics
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='micro')
recall = recall_score(y_test, y_pred, average='micro')
f1 = f1_score(y_test, y_pred, average='micro')
conf_matrix = confusion_matrix(y_test, y_pred)

# Print the evaluation metrics
print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1 Score:", f1)
print("Confusion Matrix:")
print(conf_matrix)

unique_values, counts = np.unique(y, return_counts=True)

for value, count in zip(unique_values, counts):
    print(f"{value}: {count}")

"""### **Solution**: Logistic Regression with scaling + Balancing"""

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix

X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.2, random_state=42)

## Logistic Regression (Needs Scaling + Balancing)

# Scaling for Logistic Regression!
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Initialize with class_weight='balanced'
# This forces the model to pay 3x more attention to the minority class
logreg = LogisticRegression(class_weight='balanced', random_state=42, max_iter=1000)
logreg.fit(X_train_scaled, y_train)

print("--- Logistic Regression Results ---")
y_pred_log = logreg.predict(X_test_scaled)
print(confusion_matrix(y_test, y_pred_log))
print(classification_report(y_test, y_pred_log))

"""### Here Recall (0.74 for Class 1) <--- The most important Metric for us
as it says Out of all the actual cancer cases in the dataset, how many did we find? = 74%

Accuracy of the logistic regression model after chi-squared feature selection has an accuracy of 0.749. Unfortunately, the confusion matrix, precision, and recall score prove that the model is not good at capturing the relationship between the target and features. Let's try Lasso now.

## Random Forest
"""

# Random Forest doesn't strictly need scaling, but does need balancing
rf = RandomForestClassifier(n_estimators=100,
                            class_weight='balanced',
                            random_state=42)
rf.fit(X_train, y_train)

print("--- Random Forest Results ---")
y_pred_rf = rf.predict(X_test)
print(confusion_matrix(y_test, y_pred_rf))
print(classification_report(y_test, y_pred_rf))

"""Clearly Random forest has higher Accuracy than the Linear Regression but in reality this accuracy again is **missleading** as the recall for the cancer class is droped to **22%**!

### Solution
This problem arises in random forest result is due to it takes decision based on 50% probabilty
- if probability of cancer > 50 -> it says cancer
- else benign <br/>
In our case we should drop the threshold much lower to 30% so that even if the probabilty of cancer > 30% we should mark it cancer in random forest prediction
"""

# Get the probabilities instead of just True/False
y_prob = rf.predict_proba(X_test)[:, 1]

# 2. Setting a lower threshold (30% instead of 50%)
# If the model is even  30% suspicious, we label it as Cancer (1)
custom_threshold = 0.30
y_pred_adjusted = (y_prob >= custom_threshold).astype(int)


print(f"--- Random Forest with Threshold {custom_threshold} ---")
print(confusion_matrix(y_test, y_pred_adjusted))
print(classification_report(y_test, y_pred_adjusted))

# Get the probabilities instead of just True/False
y_prob = rf.predict_proba(X_test)[:, 1]

# 2. Setting a lower threshold (30% instead of 50%)
# If the model is even  30% suspicious, we label it as Cancer (1)
custom_threshold = 0.10
y_pred_adjusted = (y_prob >= custom_threshold).astype(int)


print(f"--- Random Forest with Threshold {custom_threshold} ---")
print(confusion_matrix(y_test, y_pred_adjusted))
print(classification_report(y_test, y_pred_adjusted))

"""Here more we decrease the threshold we acheived greater recall sacrificing the accuracy so the question is where to draw the line and choose final optimal threshold.

We will take the help of the f1 sscore to get the peak thershold where Precision and Recall are best balanced
"""

import numpy as np
from sklearn.metrics import f1_score

# 1. Get the probabilities for the positive class (Cancer)
y_scores = rf.predict_proba(X_test)[:, 1]

# 2. Test thresholds from 0.01 to 1.00
thresholds = np.arange(0.01, 1.0, 0.01)
f1_scores = []

for t in thresholds:
    # Convert probabilities to 0 or 1 based on current threshold t
    y_pred_temp = (y_scores >= t).astype(int)
    # Calculate F1 score for the Cancer class (1)
    score = f1_score(y_test, y_pred_temp)
    f1_scores.append(score)

# 3. Find the best one
best_threshold = thresholds[np.argmax(f1_scores)]
max_f1 = max(f1_scores)

print(f"The Best Mathematical Threshold is: {best_threshold}")
print(f"Maximum F1 Score: {max_f1}")

import matplotlib.pyplot as plt
from sklearn.metrics import precision_recall_curve

precisions, recalls, thresholds_pr = precision_recall_curve(y_test, y_scores)


f1_scores_pr = 2 * (precisions * recalls) / (precisions + recalls)
# Locate the best F1
best_idx = np.argmax(f1_scores_pr)

plt.figure(figsize=(8, 6))
plt.plot(recalls, precisions, marker='.', label='Random Forest')
plt.scatter(recalls[best_idx], precisions[best_idx], marker='o', color='red', label='Best Threshold', zorder=10)
plt.xlabel('Recall (Sensitivity)')
plt.ylabel('Precision')
plt.title(f'Precision-Recall Curve\nBest Threshold = {thresholds_pr[best_idx]:.2f}')
plt.legend()
plt.show()

# Get the probabilities instead of just True/False
y_prob = rf.predict_proba(X_test)[:, 1]

custom_threshold = 0.26
y_pred_adjusted = (y_prob >= custom_threshold).astype(int)


print(f"--- Random Forest with Threshold {custom_threshold} ---")
print(confusion_matrix(y_test, y_pred_adjusted))
print(classification_report(y_test, y_pred_adjusted))

"""So here we achived achived greater weighted accuracy (69%) over the logistic on almost same recall value on class 1 (cancer postive mutation)

# Boosting Algorithms
"""

import numpy as np
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from sklearn.metrics import classification_report, confusion_matrix

count_neg = np.sum(y_train == 0)
count_pos = np.sum(y_train == 1)
scale_ratio = count_neg / count_pos

print(f"Negatives: {count_neg}, Positives: {count_pos}")
print(f"XGBoost Scale Ratio: {scale_ratio:.2f}")
print("\n" + "\n")

xgb = XGBClassifier(
    n_estimators=100,
    learning_rate=0.1,
    max_depth=6,
    scale_pos_weight=scale_ratio,  # Forces model to care about the minority class
    use_label_encoder=False,
    eval_metric='logloss',
    random_state=42
)

xgb.fit(X_train, y_train)

print("--- XGBoost Results ---")
y_pred_xgb = xgb.predict(X_test)
print(confusion_matrix(y_test, y_pred_xgb))
print(classification_report(y_test, y_pred_xgb))

# LightGBM is faster and often handles categorical features better.
lgbm = LGBMClassifier(
    n_estimators=100,
    learning_rate=0.1,
    class_weight='balanced', # fix for imbalance
    random_state=42,
    verbosity=-1 # Silences warning logs
)

lgbm.fit(X_train, y_train)

print("--- LightGBM Results ---")
y_pred_lgbm = lgbm.predict(X_test)
print(confusion_matrix(y_test, y_pred_lgbm))
print(classification_report(y_test, y_pred_lgbm))

## Tuning XGBoost
from sklearn.model_selection import RandomizedSearchCV

xgb_params = {
    'n_estimators': [100, 200, 300],          # How many trees?
    'learning_rate': [0.01, 0.05, 0.1, 0.2],  # How fast to learn? (Lower is usually better but slower)
    'max_depth': [3, 5, 6, 10],               # How deep is each tree? (Too deep = Overfitting)
    'subsample': [0.6, 0.8, 1.0],             # Use only % of data rows per tree
    'colsample_bytree': [0.6, 0.8, 1.0],      # Use only % of columns per tree
    'scale_pos_weight': [scale_ratio]         # KEEP THIS FIXED (Your imbalance ratio)
}

# Initialize the Base Model
xgb = XGBClassifier(objective='binary:logistic', eval_metric='logloss', use_label_encoder=False)

# Setup the Search (Try 20 random combinations)
xgb_search = RandomizedSearchCV(
    estimator=xgb,
    param_distributions=xgb_params,
    n_iter=20,
    scoring='f1',
    cv=3,
    verbose=1,
    random_state=42,
    n_jobs=-1
)

print("Tuning XGBoost... This may take a minute.")
xgb_search.fit(X_train, y_train)

print(f"Best XGBoost Params: {xgb_search.best_params_}")
best_xgb = xgb_search.best_estimator_

print("\n--- Optimized XGBoost Results ---")
y_pred_opt_xgb = best_xgb.predict(X_test)
print(classification_report(y_test, y_pred_opt_xgb))

from lightgbm import LGBMClassifier

lgbm_params = {
    'n_estimators': [100, 200, 500],
    'learning_rate': [0.01, 0.05, 0.1],
    'num_leaves': [20, 31, 50, 100],      # Key parameter for LightGBM complexity
    'max_depth': [-1, 10, 20],            # -1 means no limit (rely on num_leaves)
    'min_child_samples': [20, 50, 100],   # Prevent overfitting on small leaf nodes
    'class_weight': ['balanced']          # KEEP THIS FIXED
}

# Initialize Base Model
lgbm = LGBMClassifier(random_state=42, verbosity=-1)

# Setup Search
lgbm_search = RandomizedSearchCV(
    estimator=lgbm,
    param_distributions=lgbm_params,
    n_iter=20,
    scoring='f1',
    cv=3,
    verbose=1,
    random_state=42,
    n_jobs=-1
)

print("Tuning LightGBM...")
lgbm_search.fit(X_train, y_train)

print(f"Best LightGBM Params: {lgbm_search.best_params_}")
best_lgbm = lgbm_search.best_estimator_

print("\n--- Optimized LightGBM Results ---")
y_pred_opt_lgbm = best_lgbm.predict(X_test)
print(classification_report(y_test, y_pred_opt_lgbm))

"""# SVM & KNN"""

from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report

print("Training SVM... ")

# kernel='rbf' allows it to learn non-linear (curved) boundaries
# probability=True is REQUIRED to tune thresholds later
# class_weight='balanced' is REQUIRED for your imbalance
svm_model = SVC(kernel='rbf',
                class_weight='balanced',
                probability=True,
                random_state=42)

svm_model.fit(X_train_scaled, y_train)

print("--- SVM Results ---")
y_pred_svm = svm_model.predict(X_test_scaled)
print(classification_report(y_test, y_pred_svm))

print("Training KNN...")

# weights='distance': Closer neighbors count more than far ones (Helps with imbalance!)
# n_neighbors=5: Standard starting point
knn_model = KNeighborsClassifier(n_neighbors=5, weights='distance')

knn_model.fit(X_train_scaled, y_train)

print("--- KNN Results ---")
y_pred_knn = knn_model.predict(X_test_scaled)
print(classification_report(y_test, y_pred_knn))

"""# Deep Learning"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, confusion_matrix


device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# B. Convert Numpy Arrays to PyTorch Tensors
X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32).to(device)
y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1).to(device)
X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32).to(device)
y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).unsqueeze(1).to(device)


train_dataset = TensorDataset(X_train_tensor, y_train_tensor)
# batch_size=32
train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)

class CancerClassifier(nn.Module):
    def __init__(self, input_dim):
        super(CancerClassifier, self).__init__()

        # BLOCK 1: Expansion (Input -> 128)
        self.layer1 = nn.Linear(input_dim, 128)
        self.bn1 = nn.BatchNorm1d(128)       # <--- NEW: Stabilizes training
        self.act1 = nn.LeakyReLU(negative_slope=0.01) # <--- NEW: Prevents dead neurons
        self.drop1 = nn.Dropout(0.2)         # <--- REDUCED: Don't kill too much signal

        # BLOCK 2: Compression (128 -> 64)
        self.layer2 = nn.Linear(128, 64)
        self.bn2 = nn.BatchNorm1d(64)
        self.act2 = nn.LeakyReLU(negative_slope=0.01)
        self.drop2 = nn.Dropout(0.2)

        # BLOCK 3: Refinement (64 -> 32)
        self.layer3 = nn.Linear(64, 32)
        self.bn3 = nn.BatchNorm1d(32)
        self.act3 = nn.LeakyReLU(negative_slope=0.01)

        # Output
        self.output = nn.Linear(32, 1)

    def forward(self, x):
        # Block 1
        x = self.layer1(x)
        x = self.bn1(x)
        x = self.act1(x)
        x = self.drop1(x)

        # Block 2
        x = self.layer2(x)
        x = self.bn2(x)
        x = self.act2(x)
        x = self.drop2(x)

        # Block 3
        x = self.layer3(x)
        x = self.bn3(x)
        x = self.act3(x)

        # Output
        x = self.output(x)
        return x



input_dim = X_train_scaled.shape[1]
model = CancerClassifier(input_dim).to(device)

# Number of Negatives / Number of Positives
num_neg = np.sum(y_train == 0)
num_pos = np.sum(y_train == 1)
pos_weight_value = num_neg / num_pos
pos_weight_tensor = torch.tensor(pos_weight_value, dtype=torch.float32).to(device)

print(f"Calculated pos_weight: {pos_weight_value:.2f}")

# Loss Function: BCEWithLogitsLoss handles Sigmoid internally + Class Imbalance
criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight_tensor)
optimizer = optim.Adam(model.parameters(), lr=0.001)

epochs = 500
train_losses = []

print("Starting PyTorch Training...")

for epoch in range(epochs):
    model.train() # Set model to training mode (enables Dropout)
    running_loss = 0.0

    for batch_X, batch_y in train_loader:
        optimizer.zero_grad()
        outputs = model(batch_X)
        loss = criterion(outputs, batch_y)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()

    epoch_loss = running_loss / len(train_loader)
    train_losses.append(epoch_loss)

    if (epoch + 1) % 10 == 0:
        print(f"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}")

plt.plot(train_losses)
plt.title('Training Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.show()

model.eval()

with torch.no_grad():
    y_logits = model(X_test_tensor)
    y_probs = torch.sigmoid(y_logits).cpu().numpy()
    y_pred_pytorch = (y_probs >= 0.5).astype(int)

print("\n--- PyTorch Model Results ---")
print(confusion_matrix(y_test, y_pred_pytorch))
print(classification_report(y_test, y_pred_pytorch))

"""The mean squared error (MSE) value of 3.009 indicates that, on average, the predicted values from the XGBoost regression model deviate from the actual values by approximately 3.009 units squared. A lower MSE indicates better model performance, with a value of 0 indicating a perfect fit.

The R-squared (R2) value of 0.945 suggests that approximately 94.5% of the variance in the target variable ('cDNA_position') can be explained by the selected features and the XGBoost regression model. R2 ranges from 0 to 1, with a higher value indicating a better fit. An R2 value close to 1 indicates that the model captures most of the variance in the target variable.

In summary, the XGBoost regression model with the selected features demonstrates strong performance with a low MSE and high R2 value, indicating accurate predictions and a good fit to the data.
"""

# Create a plot of actual vs predicted values
plt.scatter(y_test, y_pred)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.title('Actual vs Predicted')
plt.show()

# Create a plot of the distribution of predicted values
sns.kdeplot(y_test, label='Actual', color='g', shade=True, linewidth=3)
sns.kdeplot(y_pred, label='Predicted', color='r', shade=True, linewidth=3)
plt.xlabel('Consequence')
plt.ylabel('Density')
plt.title('Distribution of Actual and Predicted Consequence')
plt.legend()
plt.show()

"""In summary, a few conclusions can be made from the various models I've built.
1. The allele frequency columns are significantly different
2. Logistic Regression, RFE, and XGBoost performed similarly at predicting 'CLASS' - R2 score was 0.77
3. XGBoost worked best at predicting both 'PolyPhen' and 'Consequence', providing R2 scores of 0.76 and 0.94, respectively.
4. Each model selected different features during the feature selection process, but variables such as the three allele frequency columns, cDNA_position, LoFtool, SIFT, BLOSUM62, and a few others were frequently selected.
5. There are a multitude of experiments that can extend off of this first one. Stay tuned!
"""





